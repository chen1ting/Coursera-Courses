{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Coursera-Fine-Tune-BERT-for-Text-Classification-with-TensorFlow.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zGCJYkQj_Uu2"
      },
      "source": [
        "<h2 align=center> Fine-Tune BERT for Text Classification with TensorFlow</h2>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4y2m1S6e12il"
      },
      "source": [
        "<div align=\"center\">\n",
        "    <img width=\"512px\" src='https://drive.google.com/uc?id=1fnJTeJs5HUpz7nix-F9E6EZdgUflqyEu' />\n",
        "    <p style=\"text-align: center;color:gray\">Figure 1: BERT Classification Model</p>\n",
        "</div>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eYYYWqWr_WCC"
      },
      "source": [
        "In this [project](https://www.coursera.org/projects/fine-tune-bert-tensorflow/), you will learn how to fine-tune a BERT model for text classification using TensorFlow and TF-Hub."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5yQG5PCO_WFx"
      },
      "source": [
        "The pretrained BERT model used in this project is [available](https://tfhub.dev/tensorflow/bert_en_uncased_L-12_H-768_A-12/2) on [TensorFlow Hub](https://tfhub.dev/)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7pKNS21u_WJo"
      },
      "source": [
        "### Learning Objectives"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_3NHSMXv_WMv"
      },
      "source": [
        "By the time you complete this project, you will be able to:\n",
        "\n",
        "- Build TensorFlow Input Pipelines for Text Data with the [`tf.data`](https://www.tensorflow.org/api_docs/python/tf/data) API\n",
        "- Tokenize and Preprocess Text for BERT\n",
        "- Fine-tune BERT for text classification with TensorFlow 2 and [TF Hub](https://tfhub.dev)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "o6BEe-3-AVRQ"
      },
      "source": [
        "### Prerequisites"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Sc9f-8rLAVUS"
      },
      "source": [
        "In order to be successful with this project, it is assumed you are:\n",
        "\n",
        "- Competent in the Python programming language\n",
        "- Familiar with deep learning for Natural Language Processing (NLP)\n",
        "- Familiar with TensorFlow, and its Keras API"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MYXXV5n3Ab-4"
      },
      "source": [
        "### Contents"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XhK-SYGyAjxe"
      },
      "source": [
        "This project/notebook consists of several Tasks.\n",
        "\n",
        "- **[Task 1]()**: Introduction to the Project.\n",
        "- **[Task 2]()**: Setup your TensorFlow and Colab Runtime\n",
        "- **[Task 3]()**: Download and Import the Quora Insincere Questions Dataset\n",
        "- **[Task 4]()**: Create tf.data.Datasets for Training and Evaluation\n",
        "- **[Task 5]()**: Download a Pre-trained BERT Model from TensorFlow Hub\n",
        "- **[Task 6]()**: Tokenize and Preprocess Text for BERT\n",
        "- **[Task 7]()**: Wrap a Python Function into a TensorFlow op for Eager Execution\n",
        "- **[Task 8]()**: Create a TensorFlow Input Pipeline with `tf.data`\n",
        "- **[Task 9]()**: Add a Classification Head to the BERT `hub.KerasLayer`\n",
        "- **[Task 10]()**: Fine-Tune BERT for Text Classification\n",
        "- **[Task 11]()**: Evaluate the BERT Text Classification Model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IaArqXjRAcBa"
      },
      "source": [
        "## Task 2: Setup your TensorFlow and Colab Runtime."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GDDhjzZ5A4Q_"
      },
      "source": [
        "You will only be able to use the Colab Notebook after you save it to your Google Drive folder. Click on the File menu and select “Save a copy in Drive…\n",
        "\n",
        "![Copy to Drive](https://drive.google.com/uc?id=1CH3eDmuJL8WR0AP1r3UE6sOPuqq8_Wl7)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mpe6GhLuBJWB"
      },
      "source": [
        "### Check GPU Availability\n",
        "\n",
        "Check if your Colab notebook is configured to use Graphical Processing Units (GPUs). If zero GPUs are available, check if the Colab notebook is configured to use GPUs (Menu > Runtime > Change Runtime Type).\n",
        "\n",
        "![Hardware Accelerator Settings](https://drive.google.com/uc?id=1qrihuuMtvzXJHiRV8M7RngbxFYipXKQx)\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8V9c8vzSL3aj",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2e8b948c-cebe-4219-9707-4a352ff6fa25"
      },
      "source": [
        "!nvidia-smi"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Tue May 17 04:16:19 2022       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 460.32.03    Driver Version: 460.32.03    CUDA Version: 11.2     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                               |                      |               MIG M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla T4            Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   48C    P0    28W /  70W |    778MiB / 15109MiB |      0%      Default |\n",
            "|                               |                      |                  N/A |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                                  |\n",
            "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
            "|        ID   ID                                                   Usage      |\n",
            "|=============================================================================|\n",
            "+-----------------------------------------------------------------------------+\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Obch3rAuBVf0"
      },
      "source": [
        "### Install TensorFlow and TensorFlow Model Garden"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bUQEY3dFB0jX",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6ee0ebab-99e1-43d9-80b7-a08d710e4e26"
      },
      "source": [
        "import tensorflow as tf\n",
        "print(tf.version.VERSION)"
      ],
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2.8.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aU3YLZ1TYKUt"
      },
      "source": [
        "!pip install -q tensorflow==2.3.0"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -q tf-estimator-nightly==2.8.0.dev2021122109"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Y8pJUhdCwP73",
        "outputId": "0c6097c9-905d-4188-905a-1732774d9e97"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[?25l\r\u001b[K     |▊                               | 10 kB 33.7 MB/s eta 0:00:01\r\u001b[K     |█▍                              | 20 kB 36.3 MB/s eta 0:00:01\r\u001b[K     |██▏                             | 30 kB 39.9 MB/s eta 0:00:01\r\u001b[K     |██▉                             | 40 kB 21.8 MB/s eta 0:00:01\r\u001b[K     |███▌                            | 51 kB 19.6 MB/s eta 0:00:01\r\u001b[K     |████▎                           | 61 kB 22.4 MB/s eta 0:00:01\r\u001b[K     |█████                           | 71 kB 23.0 MB/s eta 0:00:01\r\u001b[K     |█████▊                          | 81 kB 25.0 MB/s eta 0:00:01\r\u001b[K     |██████▍                         | 92 kB 27.0 MB/s eta 0:00:01\r\u001b[K     |███████                         | 102 kB 26.3 MB/s eta 0:00:01\r\u001b[K     |███████▉                        | 112 kB 26.3 MB/s eta 0:00:01\r\u001b[K     |████████▌                       | 122 kB 26.3 MB/s eta 0:00:01\r\u001b[K     |█████████▏                      | 133 kB 26.3 MB/s eta 0:00:01\r\u001b[K     |██████████                      | 143 kB 26.3 MB/s eta 0:00:01\r\u001b[K     |██████████▋                     | 153 kB 26.3 MB/s eta 0:00:01\r\u001b[K     |███████████▍                    | 163 kB 26.3 MB/s eta 0:00:01\r\u001b[K     |████████████                    | 174 kB 26.3 MB/s eta 0:00:01\r\u001b[K     |████████████▊                   | 184 kB 26.3 MB/s eta 0:00:01\r\u001b[K     |█████████████▌                  | 194 kB 26.3 MB/s eta 0:00:01\r\u001b[K     |██████████████▏                 | 204 kB 26.3 MB/s eta 0:00:01\r\u001b[K     |██████████████▉                 | 215 kB 26.3 MB/s eta 0:00:01\r\u001b[K     |███████████████▋                | 225 kB 26.3 MB/s eta 0:00:01\r\u001b[K     |████████████████▎               | 235 kB 26.3 MB/s eta 0:00:01\r\u001b[K     |█████████████████               | 245 kB 26.3 MB/s eta 0:00:01\r\u001b[K     |█████████████████▊              | 256 kB 26.3 MB/s eta 0:00:01\r\u001b[K     |██████████████████▍             | 266 kB 26.3 MB/s eta 0:00:01\r\u001b[K     |███████████████████▏            | 276 kB 26.3 MB/s eta 0:00:01\r\u001b[K     |███████████████████▉            | 286 kB 26.3 MB/s eta 0:00:01\r\u001b[K     |████████████████████▌           | 296 kB 26.3 MB/s eta 0:00:01\r\u001b[K     |█████████████████████▎          | 307 kB 26.3 MB/s eta 0:00:01\r\u001b[K     |██████████████████████          | 317 kB 26.3 MB/s eta 0:00:01\r\u001b[K     |██████████████████████▊         | 327 kB 26.3 MB/s eta 0:00:01\r\u001b[K     |███████████████████████▍        | 337 kB 26.3 MB/s eta 0:00:01\r\u001b[K     |████████████████████████        | 348 kB 26.3 MB/s eta 0:00:01\r\u001b[K     |████████████████████████▉       | 358 kB 26.3 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▌      | 368 kB 26.3 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▏     | 378 kB 26.3 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████     | 389 kB 26.3 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▋    | 399 kB 26.3 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▍   | 409 kB 26.3 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████   | 419 kB 26.3 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▊  | 430 kB 26.3 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▌ | 440 kB 26.3 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▏| 450 kB 26.3 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▉| 460 kB 26.3 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 462 kB 26.3 MB/s \n",
            "\u001b[?25h"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AFRTC-zwUy6D",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d8a277eb-2d13-48e6-ee48-286afde1c9a8"
      },
      "source": [
        "!git clone --depth 1 -b v2.3.0 https://github.com/tensorflow/models.git"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'models'...\n",
            "remote: Enumerating objects: 2650, done.\u001b[K\n",
            "remote: Counting objects: 100% (2650/2650), done.\u001b[K\n",
            "remote: Compressing objects: 100% (2311/2311), done.\u001b[K\n",
            "remote: Total 2650 (delta 505), reused 1389 (delta 306), pack-reused 0\u001b[K\n",
            "Receiving objects: 100% (2650/2650), 34.02 MiB | 35.22 MiB/s, done.\n",
            "Resolving deltas: 100% (505/505), done.\n",
            "Note: checking out '400d68abbccda2f0f6609e3a924467718b144233'.\n",
            "\n",
            "You are in 'detached HEAD' state. You can look around, make experimental\n",
            "changes and commit them, and you can discard any commits you make in this\n",
            "state without impacting any branches by performing another checkout.\n",
            "\n",
            "If you want to create a new branch to retain commits you create, you may\n",
            "do so (now or later) by using -b with the checkout command again. Example:\n",
            "\n",
            "  git checkout -b <new-branch-name>\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3H2G0571zLLs"
      },
      "source": [
        "# install requirements to use tensorflow/models repository\n",
        "!pip install -Uqr models/official/requirements.txt\n",
        "# you may have to restart the runtime afterwards"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GVjksk4yCXur"
      },
      "source": [
        "## Restart the Runtime\n",
        "\n",
        "**Note** \n",
        "After installing the required Python packages, you'll need to restart the Colab Runtime Engine (Menu > Runtime > Restart runtime...)\n",
        "\n",
        "![Restart of the Colab Runtime Engine](https://drive.google.com/uc?id=1xnjAy2sxIymKhydkqb0RKzgVK9rh3teH)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IMsEoT3Fg4Wg"
      },
      "source": [
        "## Task 3: Download and Import the Quora Insincere Questions Dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GmqEylyFYTdP"
      },
      "source": [
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "import tensorflow_hub as hub\n",
        "import sys\n",
        "sys.path.append('models')\n",
        "from official.nlp.data import classifier_data_lib\n",
        "from official.nlp.bert import tokenization\n",
        "from official.nlp import optimization"
      ],
      "execution_count": 40,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZuX1lB8pPJ-W",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "afcfe558-adb0-4444-e51b-fe7c6ec9ac47"
      },
      "source": [
        "print(\"TF Version: \", tf.__version__)\n",
        "print(\"Eager mode: \", tf.executing_eagerly())\n",
        "print(\"Hub version: \", hub.__version__)\n",
        "print(\"GPU is\", \"available\" if tf.config.experimental.list_physical_devices(\"GPU\") else \"NOT AVAILABLE\")"
      ],
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "TF Version:  2.8.0\n",
            "Eager mode:  True\n",
            "Hub version:  0.12.0\n",
            "GPU is available\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QtbwpWgyEZg7"
      },
      "source": [
        "A downloadable copy of the [Quora Insincere Questions Classification data](https://www.kaggle.com/c/quora-insincere-questions-classification/data) can be found [https://archive.org/download/fine-tune-bert-tensorflow-train.csv/train.csv.zip](https://archive.org/download/fine-tune-bert-tensorflow-train.csv/train.csv.zip). Decompress and read the data into a pandas DataFrame."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0nI-9itVwCCQ"
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "df = pd.read_csv('https://archive.org/download/fine-tune-bert-tensorflow-train.csv/train.csv.zip', compression = 'zip', low_memory = False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yeHE98KiMvDd",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "49198a0e-2585-497c-838a-1fea1f0f94ac"
      },
      "source": [
        "df.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(1306122, 3)"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "leRFRWJMocVa",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 669
        },
        "outputId": "82790558-f621-4873-e688-4e2d056d6cec"
      },
      "source": [
        "df.tail(20)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                          qid  \\\n",
              "1306102  ffff3778790af9baae76   \n",
              "1306103  ffff3f0a2449ffe4b9ff   \n",
              "1306104  ffff41393389d4206066   \n",
              "1306105  ffff42493fc203cd9532   \n",
              "1306106  ffff48dd47bee89fff79   \n",
              "1306107  ffff5fd051a032f32a39   \n",
              "1306108  ffff6d528040d3888b93   \n",
              "1306109  ffff8776cd30cdc8d7f8   \n",
              "1306110  ffff94d427ade3716cd1   \n",
              "1306111  ffffa382c58368071dc9   \n",
              "1306112  ffffa5b0fa76431c063f   \n",
              "1306113  ffffae5dbda3dc9e9771   \n",
              "1306114  ffffba7c4888798571c1   \n",
              "1306115  ffffc0c7158658a06fd9   \n",
              "1306116  ffffc404da586ac5a08f   \n",
              "1306117  ffffcc4e2331aaf1e41e   \n",
              "1306118  ffffd431801e5a2f4861   \n",
              "1306119  ffffd48fb36b63db010c   \n",
              "1306120  ffffec519fa37cf60c78   \n",
              "1306121  ffffed09fedb5088744a   \n",
              "\n",
              "                                             question_text  target  \n",
              "1306102  What steps can I take to live a normal life if...       0  \n",
              "1306103  Isn't Trump right after all? Why should the US...       1  \n",
              "1306104  Is 33 too late for a career in creative advert...       0  \n",
              "1306105  What is difference between the filteration wor...       0  \n",
              "1306106  If the universe \"popped\" into existence from n...       0  \n",
              "1306107  How does a shared service technology team meas...       0  \n",
              "1306108                    How is DSATM civil engineering?       0  \n",
              "1306109  Do you know any problem that depends solely on...       0  \n",
              "1306110  What are some comic ideas for you Tube videos ...       0  \n",
              "1306111  If you had $10 million of Bitcoin, could you s...       0  \n",
              "1306112                Are you ashamed of being an Indian?       1  \n",
              "1306113  What are the methods to determine fossil ages ...       0  \n",
              "1306114                          What is your story today?       0  \n",
              "1306115  How do I consume 150 gms protein daily both ve...       0  \n",
              "1306116  What are the good career options for a msc che...       0  \n",
              "1306117  What other technical skills do you need as a c...       0  \n",
              "1306118  Does MS in ECE have good job prospects in USA ...       0  \n",
              "1306119                          Is foam insulation toxic?       0  \n",
              "1306120  How can one start a research project based on ...       0  \n",
              "1306121  Who wins in a battle between a Wolverine and a...       0  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-af58ac62-2860-457d-8008-be8c7d3dfa57\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>qid</th>\n",
              "      <th>question_text</th>\n",
              "      <th>target</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>1306102</th>\n",
              "      <td>ffff3778790af9baae76</td>\n",
              "      <td>What steps can I take to live a normal life if...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1306103</th>\n",
              "      <td>ffff3f0a2449ffe4b9ff</td>\n",
              "      <td>Isn't Trump right after all? Why should the US...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1306104</th>\n",
              "      <td>ffff41393389d4206066</td>\n",
              "      <td>Is 33 too late for a career in creative advert...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1306105</th>\n",
              "      <td>ffff42493fc203cd9532</td>\n",
              "      <td>What is difference between the filteration wor...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1306106</th>\n",
              "      <td>ffff48dd47bee89fff79</td>\n",
              "      <td>If the universe \"popped\" into existence from n...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1306107</th>\n",
              "      <td>ffff5fd051a032f32a39</td>\n",
              "      <td>How does a shared service technology team meas...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1306108</th>\n",
              "      <td>ffff6d528040d3888b93</td>\n",
              "      <td>How is DSATM civil engineering?</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1306109</th>\n",
              "      <td>ffff8776cd30cdc8d7f8</td>\n",
              "      <td>Do you know any problem that depends solely on...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1306110</th>\n",
              "      <td>ffff94d427ade3716cd1</td>\n",
              "      <td>What are some comic ideas for you Tube videos ...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1306111</th>\n",
              "      <td>ffffa382c58368071dc9</td>\n",
              "      <td>If you had $10 million of Bitcoin, could you s...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1306112</th>\n",
              "      <td>ffffa5b0fa76431c063f</td>\n",
              "      <td>Are you ashamed of being an Indian?</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1306113</th>\n",
              "      <td>ffffae5dbda3dc9e9771</td>\n",
              "      <td>What are the methods to determine fossil ages ...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1306114</th>\n",
              "      <td>ffffba7c4888798571c1</td>\n",
              "      <td>What is your story today?</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1306115</th>\n",
              "      <td>ffffc0c7158658a06fd9</td>\n",
              "      <td>How do I consume 150 gms protein daily both ve...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1306116</th>\n",
              "      <td>ffffc404da586ac5a08f</td>\n",
              "      <td>What are the good career options for a msc che...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1306117</th>\n",
              "      <td>ffffcc4e2331aaf1e41e</td>\n",
              "      <td>What other technical skills do you need as a c...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1306118</th>\n",
              "      <td>ffffd431801e5a2f4861</td>\n",
              "      <td>Does MS in ECE have good job prospects in USA ...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1306119</th>\n",
              "      <td>ffffd48fb36b63db010c</td>\n",
              "      <td>Is foam insulation toxic?</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1306120</th>\n",
              "      <td>ffffec519fa37cf60c78</td>\n",
              "      <td>How can one start a research project based on ...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1306121</th>\n",
              "      <td>ffffed09fedb5088744a</td>\n",
              "      <td>Who wins in a battle between a Wolverine and a...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-af58ac62-2860-457d-8008-be8c7d3dfa57')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-af58ac62-2860-457d-8008-be8c7d3dfa57 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-af58ac62-2860-457d-8008-be8c7d3dfa57');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df.target.plot(kind = 'hist', title = 'Target distribution')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 298
        },
        "id": "uO386J14yHeM",
        "outputId": "2fb99990-6b85-4ec0-cc30-0869df1f5548"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<AxesSubplot:title={'center':'Target distribution'}, ylabel='Frequency'>"
            ]
          },
          "metadata": {},
          "execution_count": 7
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYIAAAEICAYAAABS0fM3AAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjUuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8qNh9FAAAACXBIWXMAAAsTAAALEwEAmpwYAAAWdklEQVR4nO3dfbRddX3n8fdHEBF5qiaOmIDxIShR6UivoOPqiJW2gMvQ1pYhBa0WiWPFNRWxUGuB0RkfaqsztliMVlGsPE7LiiWIg6UyVYKEikiiaIoRAlQiIKigGPjOH2fHOXO5N/eEe/c5nLvfr7XOYj/8zt7fX27I5+7fb599UlVIkrrrMaMuQJI0WgaBJHWcQSBJHWcQSFLHGQSS1HEGgSR1nEEgDSjJa5P8c9/6j5I8Y46O/fYkH2uWlySpJDvP0bH3a2rdaS6Op/nHINDQNf8obXs9lOT+vvVjh1TDoUk2z+YYVbV7Vd00F+epqndX1etnU0/fOTclOazv2Dc3tT44F8fX/DMnv3FIO6Kqdt+2nGQT8PqqunxHjpFk56raOte1jcJ86ovGk1cEetRIcnCSq5L8IMntSf4qyS59+yvJm5J8G/h2s+2Pmra3JXl90+ZZzb7HJfnzJDcn+V6Ss5I8PskTgEuBp/ZdiTx1inqelGR1knuTfAV45qT9/ec6MsmGJD9McmuSk6c7T5IzklyU5NNJ7gVe22z79KQSfr/p1+1JTu4779lJ/lvf+s+vOpKcA+wHfLY53x9NHmpqalid5K4kG5Oc0HesM5JckORTTV/WJ5nY8Z+mxolBoEeTB4G3AAuAFwMvB/5gUpvfAA4BliU5HDgJOAx4FnDopLbvBfYH/n2zfxFwWlX9GDgCuK0ZMtm9qm6bop4zgZ8A+wC/37ym8zfAG6pqD+B5wD/OcJ6jgIuAvYG/neaYLwOWAr8GnNI/3DOdqno1cDPwyuZ8fzZFs/OAzcBTgd8G3p3kV/r2L2/a7A2sBv5qpvNqvI1lECT5eJI7ktwwYPujm9/W1if5TNv16ZGpqmuram1Vba2qTcBHgJdOavaeqrqrqu4HjgY+UVXrq+o+4IxtjZIEWAm8pWn/Q+DdwDGD1NJMrL6KJjiq6gbgk9t5y8/ohdOeVXV3Vf3LDKe4qqourqqHmr5M5b825/468AlgxSC1b0+SfYGXAKdU1U+q6jrgY8Br+pr9c1WtaeYUzgF+cbbn1aPbWAYBcDZw+CANkywF/hh4SVU9F/jD9srSbCTZP8k/JPm3Zsjk3fSuDvrd0rf81Enr/csLgd2Aa5uhph8An2u2D2IhvTm0/mN+dzvtXwUcCXw3yReTvHiG498yw/7Jbb5Lr7+z9VRgWzD2H3tR3/q/9S3fB+w6V3cw6dFpLIOgqq4E7urfluSZST6X5Nok/yfJc5pdJwBnVtXdzXvvGHK5GtxfA98EllbVnsDbgUxq0/+43NuBxX3r+/Ytfx+4H3huVe3dvPbqm6ie6bG7W4Ctk46533SNq+qaqjoKeDJwMXDBDOcZ5LG/k8+9bVjpx/RCbpun7MCxbwOemGSPSce+dYB6NE+NZRBMYxXw5qr6JeBk4MPN9v2B/ZN8KcnaZlxZj057APcCP2qC/I0ztL8AeF2SA5LsBvzpth1V9RDwUeCDSZ4MkGRRkl9vmnwPeFKSvaY6cDMs8nfAGUl2S7IM+L2p2ibZJcmxSfaqqp81fXhokPPM4E+bcz8XeB1wfrP9OuDIJE9M8hQefpX7PWDKzzdU1S3Al4H3JNk1yYHA8cDkiWp1yLwIgiS7A/8BuDDJdfTGlvdpdu9Mb8LtUHpjrB9Nsvfwq9QATgZ+F/ghvX/Ez99e46q6FPgQcAWwEVjb7Ppp899Ttm1vhpouB57dvPebwLnATc3Q0VTDLicCu9MbKjmb3jj9dF4NbGrO85+BY3fgPNP5YlP/F4A/r6rPN9vPAb4GbAI+z8P/nN4DvKM538k83ApgCb2rg78HTt/R23c1v2Rcv5gmyRLgH6rqeUn2BG6sqn2maHcWcHVVfaJZ/wJwalVdM9SC1bokBwA3AI/zvnxpcPPiiqCq7gW+k+R3oHfHSJJtdzpcTHNbYZIF9IaKtvtpUI2PJL+Z3ucFfgF4H/BZQ0DaMWMZBEnOBa4Cnp1kc5Lj6V2KH5/ka8B6evdpA1wG3JlkA70hhLdV1Z2jqFuteANwB/Cv9D6HMNO8gqRJxnZoSJI0N8byikCSNHfG7kMiCxYsqCVLloy6DEkaK9dee+33q2rKD1SOXRAsWbKEdevWjboMSRorSab9ZLxDQ5LUcQaBJHWcQSBJHWcQSFLHGQSS1HEGgSR1nEEgSR1nEEhSxxkEktRxY/fJ4tlYcuolIzv3pve+YmTnlqTtae2KIMnHk9yR5IZp9h+b5PokX0/y5b7vD5AkDVGbQ0NnA9v7fuDvAC+tqucD76L3ncOSpCFrbWioqq5svk5yuv1f7ltdCyxuqxZJ0vQeLZPFxwOXTrczycok65Ks27JlyxDLkqT5b+RBkORl9ILglOnaVNWqqpqoqomFC6d8nLYk6REa6V1DSQ4EPgYc4fcIS9JojOyKIMl+wN8Br66qb42qDknqutauCJKcCxwKLEiyGTgdeCxAVZ0FnAY8CfhwEoCtVTXRVj2SpKm1edfQihn2vx54fVvnlyQNZuSTxZKk0TIIJKnjDAJJ6jiDQJI6ziCQpI4zCCSp4wwCSeo4g0CSOs4gkKSOMwgkqeMMAknqOINAkjrOIJCkjjMIJKnjDAJJ6jiDQJI6ziCQpI4zCCSp4wwCSeo4g0CSOs4gkKSOMwgkqeMMAknqOINAkjrOIJCkjmstCJJ8PMkdSW6YZn+SfCjJxiTXJzmorVokSdNr84rgbODw7ew/AljavFYCf91iLZKkabQWBFV1JXDXdpocBXyqetYCeyfZp616JElTG+UcwSLglr71zc22h0myMsm6JOu2bNkylOIkqSvGYrK4qlZV1URVTSxcuHDU5UjSvDLKILgV2LdvfXGzTZI0RKMMgtXAa5q7h14E3FNVt4+wHknqpJ3bOnCSc4FDgQVJNgOnA48FqKqzgDXAkcBG4D7gdW3VIkmaXmtBUFUrZthfwJvaOr8kaTBjMVksSWqPQSBJHWcQSFLHGQSS1HEGgSR1nEEgSR1nEEhSxxkEktRxBoEkdZxBIEkdZxBIUscZBJLUcQaBJHWcQSBJHWcQSFLHGQSS1HEGgSR1nEEgSR1nEEhSxxkEktRxBoEkdZxBIEkdZxBIUscZBJLUca0GQZLDk9yYZGOSU6fYv1+SK5J8Ncn1SY5ssx5J0sO1FgRJdgLOBI4AlgErkiyb1OwdwAVV9QLgGODDbdUjSZpam1cEBwMbq+qmqnoAOA84alKbAvZslvcCbmuxHknSFHZu8diLgFv61jcDh0xqcwbw+SRvBp4AHNZiPZKkKYx6sngFcHZVLQaOBM5J8rCakqxMsi7Jui1btgy9SEmaz9oMgluBffvWFzfb+h0PXABQVVcBuwILJh+oqlZV1URVTSxcuLClciWpm9oMgmuApUmenmQXepPBqye1uRl4OUCSA+gFgb/yS9IQDRQESZ6/oweuqq3AicBlwDfo3R20Psk7kyxvmr0VOCHJ14BzgddWVe3ouSRJj9ygk8UfTvI44Gzgb6vqnkHeVFVrgDWTtp3Wt7wBeMmANUiSWjDQFUFV/TJwLL0x/2uTfCbJr7ZamSRpKAaeI6iqb9P7ANgpwEuBDyX5ZpLfaqs4SVL7Bp0jODDJB+mN9f8K8MqqOqBZ/mCL9UmSWjboHMFfAh8D3l5V92/bWFW3JXlHK5VJkoZi0CB4BXB/VT0I0Hzoa9equq+qzmmtOklS6wadI7gceHzf+m7NNknSmBs0CHatqh9tW2mWd2unJEnSMA0aBD9OctC2lSS/BNy/nfaSpDEx6BzBHwIXJrkNCPAU4D+1VZQkaXgGCoKquibJc4BnN5turKqftVeWJGlYduT7CF4ILGnec1ASqupTrVQlSRqagYIgyTnAM4HrgAebzQUYBJI05ga9IpgAlvlkUEmafwa9a+gGehPEkqR5ZtArggXAhiRfAX66bWNVLZ/+LZKkcTBoEJzRZhGSpNEZ9PbRLyZ5GrC0qi5PshuwU7ulSZKGYdDHUJ8AXAR8pNm0CLi4pZokSUM06GTxm+h9peS98PMvqXlyW0VJkoZn0CD4aVU9sG0lyc70PkcgSRpzgwbBF5O8HXh8813FFwKfba8sSdKwDBoEpwJbgK8DbwDW0Pv+YknSmBv0rqGHgI82L0nSPDLos4a+wxRzAlX1jDmvSJI0VDvyrKFtdgV+B3ji3JcjSRq2geYIqurOvtetVfU/6H2h/XYlOTzJjUk2Jjl1mjZHJ9mQZH2Sz+xY+ZKk2Rp0aOigvtXH0LtC2O57k+wEnAn8KrAZuCbJ6qra0NdmKfDHwEuq6u4kfjZBkoZs0KGhv+hb3gpsAo6e4T0HAxur6iaAJOcBRwEb+tqcAJxZVXcDVNUdA9YjSZojg9419LJHcOxFwC1965uBQya12R8gyZfoPbvojKr63OQDJVkJrATYb7/9HkEpkqTpDDo0dNL29lfVB2Zx/qXAocBi4Mokz6+qH0w6/ipgFcDExISfaJakObQjdw29EFjdrL8S+Arw7e2851Zg3771xc22fpuBq6vqZ8B3knyLXjBcM2BdkqRZGjQIFgMHVdUPAZKcAVxSVcdt5z3XAEuTPJ1eABwD/O6kNhcDK4BPJFlAb6jopoGrlyTN2qCPmPh3wAN96w8026ZVVVuBE4HLgG8AF1TV+iTvTLLtm80uA+5MsgG4AnhbVd25Ix2QJM3OoFcEnwK+kuTvm/XfAD4505uqag295xL1bzutb7mAk5qXJGkEBr1r6L8nuRT45WbT66rqq+2VJUkalkGHhgB2A+6tqv8JbG7G/iVJY27Qr6o8HTiF3qeAAR4LfLqtoiRJwzPoFcFvAsuBHwNU1W3AHm0VJUkankGD4IFmYrcAkjyhvZIkScM0aBBckOQjwN5JTgAuxy+pkaR5Yca7hpIEOB94DnAv8GzgtKr63y3XJkkaghmDoKoqyZqqej7gP/6SNM8MOjT0L0le2GolkqSRGPSTxYcAxyXZRO/OodC7WDiwrcIkScMx07eM7VdVNwO/PqR6JElDNtMVwcX0njr63ST/q6peNYSaJElDNNMcQfqWn9FmIZKk0ZgpCGqaZUnSPDHT0NAvJrmX3pXB45tl+H+TxXu2Wp0kqXXbDYKq2mlYhUiSRmNHHkMtSZqHDAJJ6jiDQJI6ziCQpI4zCCSp4wwCSeo4g0CSOs4gkKSOMwgkqeNaDYIkhye5McnGJKdup92rklSSiTbrkSQ9XGtBkGQn4EzgCGAZsCLJsina7QH8F+DqtmqRJE2vzSuCg4GNVXVTVT0AnAccNUW7dwHvA37SYi2SpGm0GQSLgFv61jc3234uyUHAvlV1yfYOlGRlknVJ1m3ZsmXuK5WkDhvZZHGSxwAfAN46U9uqWlVVE1U1sXDhwvaLk6QOaTMIbgX27Vtf3GzbZg/gecA/JdkEvAhY7YSxJA1Xm0FwDbA0ydOT7AIcA6zetrOq7qmqBVW1pKqWAGuB5VW1rsWaJEmTtBYEVbUVOBG4DPgGcEFVrU/yziTL2zqvJGnHzPRVlbNSVWuANZO2nTZN20PbrEWSNDU/WSxJHWcQSFLHGQSS1HEGgSR1nEEgSR1nEEhSxxkEktRxBoEkdZxBIEkdZxBIUscZBJLUcQaBJHWcQSBJHWcQSFLHGQSS1HEGgSR1nEEgSR1nEEhSxxkEktRxBoEkdZxBIEkdZxBIUscZBJLUcQaBJHWcQSBJHddqECQ5PMmNSTYmOXWK/Scl2ZDk+iRfSPK0NuuRJD1ca0GQZCfgTOAIYBmwIsmySc2+CkxU1YHARcCftVWPJGlqbV4RHAxsrKqbquoB4DzgqP4GVXVFVd3XrK4FFrdYjyRpCm0GwSLglr71zc226RwPXDrVjiQrk6xLsm7Lli1zWKIk6VExWZzkOGACeP9U+6tqVVVNVNXEwoULh1ucJM1zO7d47FuBffvWFzfb/j9JDgP+BHhpVf20xXokSVNo84rgGmBpkqcn2QU4Bljd3yDJC4CPAMur6o4Wa5EkTaO1IKiqrcCJwGXAN4ALqmp9kncmWd40ez+wO3BhkuuSrJ7mcJKklrQ5NERVrQHWTNp2Wt/yYW2eX5I0s0fFZLEkaXQMAknqOINAkjrOIJCkjjMIJKnjDAJJ6jiDQJI6ziCQpI4zCCSp4wwCSeo4g0CSOs4gkKSOMwgkqeMMAknquFYfQy1J882SUy8Z2bk3vfcVrRzXKwJJ6jiDQJI6ziCQpI4zCCSp4wwCSeo4g0CSOs4gkKSOMwgkqeMMAknqOINAkjqu1SBIcniSG5NsTHLqFPsfl+T8Zv/VSZa0WY8k6eFaC4IkOwFnAkcAy4AVSZZNanY8cHdVPQv4IPC+tuqRJE2tzSuCg4GNVXVTVT0AnAccNanNUcAnm+WLgJcnSYs1SZImafPpo4uAW/rWNwOHTNemqrYmuQd4EvD9/kZJVgIrm9UfJbnxEda0YPKxhyWju9YZWZ9HyD53Q+f6nPfNqs9Pm27HWDyGuqpWAatme5wk66pqYg5KGhv2uRvscze01ec2h4ZuBfbtW1/cbJuyTZKdgb2AO1usSZI0SZtBcA2wNMnTk+wCHAOsntRmNfB7zfJvA/9YVdViTZKkSVobGmrG/E8ELgN2Aj5eVeuTvBNYV1Wrgb8BzkmyEbiLXli0adbDS2PIPneDfe6GVvocfwGXpG7zk8WS1HEGgSR13LwMgi4+2mKAPp+UZEOS65N8Icm09xSPi5n63NfuVUkqydjfajhIn5Mc3fys1yf5zLBrnGsD/N3eL8kVSb7a/P0+chR1zpUkH09yR5IbptmfJB9q/jyuT3LQrE9aVfPqRW9i+l+BZwC7AF8Dlk1q8wfAWc3yMcD5o657CH1+GbBbs/zGLvS5abcHcCWwFpgYdd1D+DkvBb4K/EKz/uRR1z2EPq8C3tgsLwM2jbruWfb5PwIHATdMs/9I4FIgwIuAq2d7zvl4RdDFR1vM2OequqKq7mtW19L7XMc4G+TnDPAues+w+skwi2vJIH0+ATizqu4GqKo7hlzjXBukzwXs2SzvBdw2xPrmXFVdSe8uyukcBXyqetYCeyfZZzbnnI9BMNWjLRZN16aqtgLbHm0xrgbpc7/j6f1GMc5m7HNzybxvVV0yzMJaNMjPeX9g/yRfSrI2yeFDq64dg/T5DOC4JJuBNcCbh1PayOzo/+8zGotHTGjuJDkOmABeOupa2pTkMcAHgNeOuJRh25ne8NCh9K76rkzy/Kr6wSiLatkK4Oyq+oskL6b32aTnVdVDoy5sXMzHK4IuPtpikD6T5DDgT4DlVfXTIdXWlpn6vAfwPOCfkmyiN5a6eswnjAf5OW8GVlfVz6rqO8C36AXDuBqkz8cDFwBU1VXArvQeSDdfDfT/+46Yj0HQxUdbzNjnJC8APkIvBMZ93Bhm6HNV3VNVC6pqSVUtoTcvsryq1o2m3DkxyN/ti+ldDZBkAb2hopuGWONcG6TPNwMvB0hyAL0g2DLUKodrNfCa5u6hFwH3VNXtszngvBsaqkfnoy1aNWCf3w/sDlzYzIvfXFXLR1b0LA3Y53llwD5fBvxakg3Ag8Dbqmpsr3YH7PNbgY8meQu9iePXjvMvdknOpRfmC5p5j9OBxwJU1Vn05kGOBDYC9wGvm/U5x/jPS5I0B+bj0JAkaQcYBJLUcQaBJHWcQSBJHWcQSFLHGQSS1HEGgSR13P8FdJXGehzQddcAAAAASUVORK5CYII=\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ELjswHcFHfp3"
      },
      "source": [
        "## Task 4: Create tf.data.Datasets for Training and Evaluation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fScULIGPwuWk",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b44f391e-4b70-4060-ed16-eb7cecd3bf8f"
      },
      "source": [
        "# use 0.0075 in training set is for sake of a relatively fast running of the train dataset\n",
        "# stratify means to follow the distribution of original df for the test and train df\n",
        "train_df, remaining = train_test_split(df, random_state=42, train_size=0.0075, stratify=df.target.values)\n",
        "# use 0.00075 in testing set is to achieve a test dataset of approximatly 1/10 of the train set, without containing any entries within the train set\n",
        "valid_df, _ = train_test_split(remaining, random_state=42, train_size=0.00075, stratify=remaining.target.values)\n",
        "train_df.shape, valid_df.shape\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((9795, 3), (972, 3))"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qQYMGT5_qLPX",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ff88d01d-266a-462f-e24a-1ac3afb66e03"
      },
      "source": [
        "# create a tf.data object for faster pipeline input preprocessing, the object created is a python iterable, so that we can execute easily\n",
        "with tf.device('/cpu:0'):\n",
        "  train_data = tf.data.Dataset.from_tensor_slices((train_df.question_text.values, train_df.target.values))\n",
        "  valid_data = tf.data.Dataset.from_tensor_slices((valid_df['question_text'].values, valid_df['target'].values))\n",
        "\n",
        "  for text, label in train_data.take(1):\n",
        "    print(text)\n",
        "    print(label)\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tf.Tensor(b'Why are unhealthy relationships so desirable?', shape=(), dtype=string)\n",
            "tf.Tensor(0, shape=(), dtype=int64)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e2-ReN88Hvy_"
      },
      "source": [
        "## Task 5: Download a Pre-trained BERT Model from TensorFlow Hub"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EMb5M86b4-BU"
      },
      "source": [
        "\"\"\"\n",
        "Each line of the dataset is composed of the review text and its label\n",
        "- Data preprocessing consists of transforming text to BERT input features:\n",
        "input_word_ids, input_mask, segment_ids\n",
        "- In the process, tokenizing the text is done with the provided BERT model tokenizer\n",
        "\"\"\"\n",
        "label_list = [0, 1] # Label categories\n",
        "max_seq_length = 128 # maximum length of (token) input sequences, usually max is 512, better explore afterwards\n",
        "train_batch_size = 32\n",
        "\n",
        "# Get BERT layer and tokenizer:\n",
        "# More details here: https://tfhub.dev/tensorflow/bert_en_uncased_L-12_H-768_A-12/2\n",
        "bert_layer = hub.KerasLayer(\"https://tfhub.dev/tensorflow/bert_en_uncased_L-12_H-768_A-12/2\", trainable=True)\n",
        "\n",
        "# Get the vocabulary files from pre-trained module\n",
        "vocab_file = bert_layer.resolved_object.vocab_file.asset_path.numpy()\n",
        "# Check that all training data is in lower case\n",
        "do_lower_case = bert_layer.resolved_object.do_lower_case.numpy()\n",
        "# Instantiate tokenrizer(preprocessing of bert)\n",
        "tokenizer = tokenization.FullTokenizer(vocab_file, do_lower_case)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wEUezMK-zkkI",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "69515aa1-c2e0-41e9-c9b3-f20f14b15253"
      },
      "source": [
        "# perform tokenization\n",
        "tokenizer.wordpiece_tokenizer.tokenize('hi, how are you doing?')\n",
        "# '##' in the token means that the symbol is attached to a character"
      ],
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['hi', '##,', 'how', 'are', 'you', 'doing', '##?']"
            ]
          },
          "metadata": {},
          "execution_count": 42
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5AFsmTO5JSmc",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c1aaa17e-ac7e-48b6-8573-b677ace5955c"
      },
      "source": [
        "tokenizer.convert_tokens_to_ids(tokenizer.wordpiece_tokenizer.tokenize('hi, how are you doing?'))"
      ],
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[7632, 29623, 2129, 2024, 2017, 2725, 29632]"
            ]
          },
          "metadata": {},
          "execution_count": 43
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9QinzNq6OsP1"
      },
      "source": [
        "## Task 6: Tokenize and Preprocess Text for BERT"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3FTqJ698zZ1e"
      },
      "source": [
        "<div align=\"center\">\n",
        "    <img width=\"512px\" src='https://drive.google.com/uc?id=1-SpKFELnEvBMBqO7h3iypo8q9uUUo96P' />\n",
        "    <p style=\"text-align: center;color:gray\">Figure 2: BERT Tokenizer</p>\n",
        "</div>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cWYkggYe6HZc"
      },
      "source": [
        "We'll need to transform our data into a format BERT understands. This involves two steps. First, we create InputExamples using `classifier_data_lib`'s constructor `InputExample` provided in the BERT library."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m-21A5aNJM0W"
      },
      "source": [
        "# This provides a function to convert row to input features and label\n",
        "# input features needed: token ids, input mask, input type ids(0 for masked words prediction, 1 for next sentence prediction(NSP))\n",
        "def to_feature(text, label, label_list=label_list, max_seq_length=max_seq_length, tokenizer=tokenizer):\n",
        "  example = classifier_data_lib.InputExample(guid=None, # guid is the id for each example(since we are only dealing with 1 example at a time, set guid to none; )\n",
        "                                             text_a = text.numpy(), \n",
        "                                             text_b = None, # text_b is a parameter used to specify the next sentence in NSP (since we are not doing NSP, set it to none)\n",
        "                                             label = label.numpy())\n",
        "  feature = classifier_data_lib.convert_single_example(0, example, label_list, max_seq_length, tokenizer)\n",
        "  return (feature.input_ids, feature.input_mask, feature.segment_ids, feature.label_id)\n",
        "  "
      ],
      "execution_count": 45,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "A_HQSsHwWCsK"
      },
      "source": [
        "You want to use [`Dataset.map`](https://www.tensorflow.org/api_docs/python/tf/data/Dataset#map) to apply this function to each element of the dataset. [`Dataset.map`](https://www.tensorflow.org/api_docs/python/tf/data/Dataset#map) runs in graph mode.\n",
        "\n",
        "- Graph tensors do not have a value.\n",
        "- In graph mode you can only use TensorFlow Ops and functions.\n",
        "\n",
        "So you can't `.map` this function directly: You need to wrap it in a [`tf.py_function`](https://www.tensorflow.org/api_docs/python/tf/py_function). The [`tf.py_function`](https://www.tensorflow.org/api_docs/python/tf/py_function) will pass regular tensors (with a value and a `.numpy()` method to access it), to the wrapped python function."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zaNlkKVfWX0Q"
      },
      "source": [
        "## Task 7: Wrap a Python Function into a TensorFlow op for Eager Execution"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AGACBcfCWC2O"
      },
      "source": [
        "# This function takes in each example in out dataset and convert it to the format that bert requires\n",
        "def to_feature_map(text, label):\n",
        "  input_ids, input_mask, segment_ids, label_id = tf.py_function(func=to_feature, \n",
        "                                                                inp=[text, label],\n",
        "                                                                Tout=[tf.int32, tf.int32, tf.int32, tf.int32]) # Convert a graph tensow to regular tensor\n",
        "  # We need to specify set id because wrapper doesn't automatically do it for us\n",
        "  input_ids.set_shape([max_seq_length])\n",
        "  input_mask.set_shape([max_seq_length])\n",
        "  segment_ids.set_shape([max_seq_length])\n",
        "  label_id.set_shape([])\n",
        "  \n",
        "  x = {\n",
        "      'input_word_ids':input_ids,\n",
        "       'input_mask':input_mask,\n",
        "       'input_type_ids':segment_ids\n",
        "  }\n",
        "\n",
        "  return (x, label_id)"
      ],
      "execution_count": 48,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dhdO6MjTbtn1"
      },
      "source": [
        "## Task 8: Create a TensorFlow Input Pipeline with `tf.data`"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LHRdiO3dnPNr",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 514
        },
        "outputId": "66880b24-94e1-4b9b-dfda-bed5e8b4251b"
      },
      "source": [
        "with tf.device('/cpu:0'):\n",
        "  # train\n",
        "  # num_parallel_calls is for parallel execution of mapping. AUTOTUNE is used to automatically decide the best parallelization level\n",
        "  train_data = (train_data.map(to_feature_map,\n",
        "                               num_parallel_calls=tf.data.experimental.AUTOTUNE)\n",
        "  .shuffle(1000)\n",
        "  .batch(32, drop_remainder=True)\n",
        "  .prefetch(tf.data.experimental.AUTOTUNE)) # prefetch is used to minimize I/0 bottolneck with prefetching of data\n",
        "\n",
        "  # valid\n",
        "  valid_data = (valid_data.map(to_feature_map,\n",
        "                               num_parallel_calls=tf.data.experimental.AUTOTUNE)\n",
        "  .batch(32, drop_remainder=True) #valid_df doesn't requires shuffle operation\n",
        "  .prefetch(tf.data.experimental.AUTOTUNE))\n",
        "  \n",
        "  "
      ],
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "error",
          "ename": "TypeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-49-2db14bf2cb85>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m   \u001b[0;31m# num_parallel_calls is for parallel execution of mapping. AUTOTUNE is used to automatically decide the best parallelization level\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m   train_data = (train_data.map(to_feature_map,\n\u001b[0;32m----> 5\u001b[0;31m                                num_parallel_calls=tf.data.experimental.AUTOTUNE)\n\u001b[0m\u001b[1;32m      6\u001b[0m   \u001b[0;34m.\u001b[0m\u001b[0mshuffle\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1000\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m   \u001b[0;34m.\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m32\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdrop_remainder\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/data/ops/dataset_ops.py\u001b[0m in \u001b[0;36mmap\u001b[0;34m(self, map_func, num_parallel_calls, deterministic, name)\u001b[0m\n\u001b[1;32m   2022\u001b[0m           nest.flatten(output_classes), nest.flatten(state_classes)):\n\u001b[1;32m   2023\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0missubclass\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnew_state_class\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstate_class\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2024\u001b[0;31m           raise TypeError(\n\u001b[0m\u001b[1;32m   2025\u001b[0m               \u001b[0;34m\"The element classes for the new state must match the initial \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2026\u001b[0m               \u001b[0;34m\"state. Expected %s; got %s.\"\u001b[0m \u001b[0;34m%\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/data/ops/dataset_ops.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, input_dataset, map_func, num_parallel_calls, deterministic, use_inter_op_parallelism, preserve_cardinality, use_legacy_function, name)\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/data/ops/structured_function.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, func, transformation_name, dataset, input_classes, input_shapes, input_types, input_structure, add_to_graph, use_legacy_function, defun_kwargs)\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36mget_concrete_function\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   3069\u001b[0m             \u001b[0mkwargs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3070\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minput_signature\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3071\u001b[0;31m             \u001b[0mautograph\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_autograph\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3072\u001b[0m             \u001b[0mautograph_options\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_autograph_options\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3073\u001b[0m             \u001b[0marg_names\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0marg_names\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_get_concrete_function_garbage_collected\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   3034\u001b[0m         \u001b[0mdevice_functions\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3035\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3036\u001b[0;31m     \u001b[0min_cross_replica_context\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3037\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3038\u001b[0m       \u001b[0min_cross_replica_context\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mstrategy_stack\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreplica_context\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_maybe_define_function\u001b[0;34m(self, args, kwargs)\u001b[0m\n\u001b[1;32m   3290\u001b[0m   \u001b[0mgenerated\u001b[0m \u001b[0mgraphs\u001b[0m \u001b[0macross\u001b[0m \u001b[0mmultiple\u001b[0m \u001b[0mmachines\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3291\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3292\u001b[0;31m   \u001b[0m_Example\u001b[0m \u001b[0mUsage_\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3293\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3294\u001b[0m   \u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0mpython\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_create_graph_function\u001b[0;34m(self, args, kwargs, override_flat_arg_shapes)\u001b[0m\n\u001b[1;32m   3138\u001b[0m           \u001b[0mnest\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mflatten\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexpand_composites\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3139\u001b[0m           expand_composites=True)\n\u001b[0;32m-> 3140\u001b[0;31m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3141\u001b[0m     graph_function = self._create_graph_function(\n\u001b[1;32m   3142\u001b[0m         args, kwargs, override_flat_arg_shapes=relaxed_arg_shapes)\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/func_graph.py\u001b[0m in \u001b[0;36mfunc_graph_from_py_func\u001b[0;34m(name, python_func, args, kwargs, signature, func_graph, autograph, autograph_options, add_control_dependencies, arg_names, op_return_value, collections, capture_by_value, override_flat_arg_shapes, acd_record_initial_resource_uses)\u001b[0m\n\u001b[1;32m   1159\u001b[0m       \u001b[0;31m`\u001b[0m\u001b[0margs\u001b[0m\u001b[0;31m`\u001b[0m \u001b[0mare\u001b[0m \u001b[0minstances\u001b[0m \u001b[0mof\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;31m`\u001b[0m \u001b[0mmust\u001b[0m \u001b[0mhave\u001b[0m \u001b[0ma\u001b[0m \u001b[0mcorresponding\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0mTensorShape\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1160\u001b[0m       \u001b[0;32min\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0mflat_shapes\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;34m.\u001b[0m  \u001b[0mMay\u001b[0m \u001b[0mbe\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mwhich\u001b[0m \u001b[0mcase\u001b[0m \u001b[0mexact\u001b[0m \u001b[0mshapes\u001b[0m \u001b[0mare\u001b[0m \u001b[0mread\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1161\u001b[0;31m       \u001b[0mdirectly\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mthe\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1162\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1163\u001b[0m   \u001b[0mReturns\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/data/ops/structured_function.py\u001b[0m in \u001b[0;36mwrapped_fn\u001b[0;34m(*args)\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/data/ops/structured_function.py\u001b[0m in \u001b[0;36mwrapper_helper\u001b[0;34m(*args)\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/autograph/impl/api.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    690\u001b[0m   \u001b[0mUnlike\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunction\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0mto_graph\u001b[0m\u001b[0;31m`\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0ma\u001b[0m \u001b[0mlow\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mlevel\u001b[0m \u001b[0mtranspiler\u001b[0m \u001b[0mthat\u001b[0m \u001b[0mconverts\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    691\u001b[0m   \u001b[0mPython\u001b[0m \u001b[0mcode\u001b[0m \u001b[0mto\u001b[0m \u001b[0mTensorFlow\u001b[0m \u001b[0mgraph\u001b[0m \u001b[0mcode\u001b[0m\u001b[0;34m.\u001b[0m \u001b[0mIt\u001b[0m \u001b[0mdoes\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mimplement\u001b[0m \u001b[0many\u001b[0m \u001b[0mcaching\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 692\u001b[0;31m   \u001b[0mvariable\u001b[0m \u001b[0mmanagement\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mcreate\u001b[0m \u001b[0many\u001b[0m \u001b[0mactual\u001b[0m \u001b[0mops\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0mbest\u001b[0m \u001b[0mused\u001b[0m \u001b[0mwhere\u001b[0m \u001b[0mgreater\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    693\u001b[0m   \u001b[0mcontrol\u001b[0m \u001b[0mover\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mgenerated\u001b[0m \u001b[0mTensorFlow\u001b[0m \u001b[0mgraph\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0mdesired\u001b[0m\u001b[0;34m.\u001b[0m \u001b[0mAnother\u001b[0m \u001b[0mdifference\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    694\u001b[0m   \u001b[0;32mfrom\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunction\u001b[0m\u001b[0;31m`\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0mthat\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0mto_graph\u001b[0m\u001b[0;31m`\u001b[0m \u001b[0mwill\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mwrap\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mgraph\u001b[0m \u001b[0minto\u001b[0m \u001b[0ma\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mTypeError\u001b[0m: in user code:\n\n    File \"<ipython-input-48-6c57aa34e216>\", line 3, in to_feature_map  *\n        input_ids, input_mask, segment_ids, label_id = tf.py_function(func=to_feature,\n\n    TypeError: Tensors in list passed to 'input' of 'EagerPyFunc' Op have types [<NOT CONVERTIBLE TO TENSOR>, int32] that are invalid. Tensors: [{'input_word_ids': <tf.Tensor 'args_2:0' shape=(32, 128) dtype=int32>, 'input_mask': <tf.Tensor 'args_0:0' shape=(32, 128) dtype=int32>, 'input_type_ids': <tf.Tensor 'args_1:0' shape=(32, 128) dtype=int32>}, <tf.Tensor 'args_3:0' shape=(32,) dtype=int32>]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KLUWnfx-YDi2"
      },
      "source": [
        "The resulting `tf.data.Datasets` return `(features, labels)` pairs, as expected by [`keras.Model.fit`](https://www.tensorflow.org/api_docs/python/tf/keras/Model#fit):"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B0Z2cy9GHQ8x"
      },
      "source": [
        "# train data spec\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DGAH-ycYOmao"
      },
      "source": [
        "# valid data spec\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GZxe-7yhPyQe"
      },
      "source": [
        "## Task 9: Add a Classification Head to the BERT Layer"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9THH5V0Dw2HO"
      },
      "source": [
        "<div align=\"center\">\n",
        "    <img width=\"512px\" src='https://drive.google.com/uc?id=1fnJTeJs5HUpz7nix-F9E6EZdgUflqyEu' />\n",
        "    <p style=\"text-align: center;color:gray\">Figure 3: BERT Layer</p>\n",
        "</div>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G9il4gtlADcp"
      },
      "source": [
        "# Building the model\n",
        "def create_model():\n",
        "  "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "S6maM-vr7YaJ"
      },
      "source": [
        "## Task 10: Fine-Tune BERT for Text Classification"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ptCtiiONsBgo"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6GJaFnkbMtPL"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OcREcgPUHr9O"
      },
      "source": [
        "# Train model\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kNZl1lx_cA5Y"
      },
      "source": [
        "## Task 11: Evaluate the BERT Text Classification Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dCjgrUYH_IsE"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "def plot_graphs(history, metric):\n",
        "  plt.plot(history.history[metric])\n",
        "  plt.plot(history.history['val_'+metric], '')\n",
        "  plt.xlabel(\"Epochs\")\n",
        "  plt.ylabel(metric)\n",
        "  plt.legend([metric, 'val_'+metric])\n",
        "  plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v6lrFRra_KmA"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "opu9neBA_98R"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hkhtCCgnUbY6"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K4B8NQBLd9rN"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FeVNOGfFJT9O"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I_YWudFRJT__"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hENB__IlJUCk"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wkYpiGrhJUFK"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iYqbQZJnJUHw"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aiKuBGgfJUKv"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}